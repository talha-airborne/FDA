# FDA
Syed Mohammad Talha (24577)'s FDA Work (Assignments, Projects, Practice)

Explaination of file 1

I begin by importing and cleaning financial data, folloId by computations of key performance metrics such as revenue, cost, profit, and growth. Using Python libraries like pandas, the code manipulates and structures the data for analysis. The calculations involve deriving the total profit by subtracting total costs from revenues and then evaluating how these metrics vary over time. Visualization libraries like matplotlib and seaborn are used to present this data visually — and bar graphs and line plots that track revenue and profit trends across months or departments. The core purpose is to understand how financial data can be interpreted programmatically and visually. The end result is a clear picture of business performance, helping us identify periods of profitability, underperformance, or potential cost overruns. It teaches basic finance concepts through coding and supports decision-making in a corporate context.

Explaination of file 2

The objective is to build a machine learning model that predicts the success or failure of startups based on various features such as funding amount, sector of operation, and geographical location. The project follows a standard machine learning pipeline: data loading, cleaning, preprocessing, model training, and evaluation. Categorical variables like ‘country’ and ‘sector’ are encoded into numerical form using label encoding. The data is then split into training and testing sets. Logistic Regressionis implemented and trained using Scikit-learn. It evaluates the model based on their accuracy and prediction ability. A confusion matrix is used to assess how Ill the models distinguish betIen successful and failed startups. The results show which features are most indicative of startup success and offer a basic yet functional prediction system.

Explaination of file 3

This project is about student academic performance data and aims to uncover the impact of various socio-demographic and behavioral factors on academic success. The dataset includes variables such as gender, parental education, study time, school support, and previous scores. I first perform exploratory data analysis (EDA), using libraries like seaborn to plot relationships and distributions. Correlation matrices and boxplots are used to identify trends and possible predictors of high or low performance. After understanding the data visually, I proceed to train regression models — likely Linear Regression or Decision Trees — to predict final grades based on the input variables. The code includes splitting the dataset, fitting the models, and assessing prediction accuracy using metrics like Mean Squared Error or R². The outcome of this analysis is a set of insights on which features most heavily impact student grades. For instance, study time and parental education level are usually positive indicators. This project is a strong example of how data science can support educational policy and student support services.

Explaination of file 4

This project focuses on retail sales forecasting, with the goal of predicting future sales based on historical data. The dataset contains date-wise sales figures and categorical data like store or product ID, is first cleaned and prepared using pandas. Time series visualizations are created to explore trends, seasonality, and anomalies. The analysis then transitions into building a predictive model using a regression algorithm. The code splits the data into training and test sets, and fits the model. After training, predictions are made for unseen data to forecast future sales. The output includes both numeric sales forecasts and visual charts comparing predicted vs. actual sales. The project demonstrates the business value of forecasting, helping with inventory control, revenue planning, and campaign scheduling.


This project performs customer segmentation using unsupervised learning, specifically the K-Means clustering algorithm. The goal is to divide customers into meaningful groups based on their behaviors or demographics, allowing the business to customize its offerings. The dataset  includes features such as age, income, etc. These are first scaled using standardization techniques (like StandardScaler) to ensure fair clustering. The elbow method is used to determine the optimal number of clusters by plotting within-cluster sum of squares (WCSS) against the number of clusters. Once the number of clusters is chosen (k=4), the K-Means algorithm assigns each customer to a group. These groups are then analyzed to describe each customer type — such as high-income high-spenders, low-income budget buyers, or middle-income average spenders. The notebook visualizes these clusters using scatter plots. The result is a segmentation model that can drive personalized marketing, loyalty programs, and better customer retention strategies. It exemplifies how unsupervised learning creates real business value by revealing hidden patterns in customer behavior.

